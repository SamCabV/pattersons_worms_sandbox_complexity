# Question: What is your understanding of the experiment the team is replicating?  What question does it answer?  How clear is the team's explanation?

The team seems to be replicating an agent based cellular automaton model to simulate a simplified version of driver behavior and interactions. The abstract does not seem to lay out a clear question that will be answered with a measurable goal. In the prediction explanation section, there is a graph that seems to answer the question “how does the number of cards affect the number of collisions over time?”. The abstract could use more clarifying as to what is being asked, to better allude to graphs that answer those questions later in the paper.

# Methodology: Do you understand the methodology?  Does it make sense for the question?  Are there limitations you see that the team did not address?

Beyond the statement of the techniques used, in this case agent based modeling, the report could do a better job at clarifying the more technical parts of the implementation and what sets this implementation apart from other agent based models. Since the question being posed is uncertain, it is hard to say if these tools are fit. More explanation on the limits of the model would also be nice.

# Results: Do you understand what the results are (not yet considering their interpretation)?  If they are presented graphically, are the visualizations effective?  Do all figures have labels on the axes and captions?

The results are understandable, if the question is something like “how does the number of cards affect the number of collisions over time?”. A key on the figure would be nice to better understand what the different shapes mean. 

# Interpretation: Does the draft report interpret the results as an answer to the motivating question?  Does the argument hold water?
	
The interpretation of the data with the mock-up model makes sense, that being said it's hard to say more since the implementation is not complete. 

# Replication: Are the results in the report consistent with the results from the original paper?  If so, how did the authors demonstrate that consistency?  Is it quantitative or qualitative?

No examples of the original paper are given to compare to.

# Extension: Does the report explain an extension to the original experiment clearly?  Can it answer an interesting question that the original experiment did not answer?
	
The extension of anti-collision is explained, but its relevance to answer questions not on the paper is not well explained. 

# Progress: Is the team roughly where they should be at this point, with a replication that is substantially complete and an extension that is clearly defined and either complete or nearly so?
	
They seem to be a little behind. Both with the implementation and the extension.
